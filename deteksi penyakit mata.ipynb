{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import cv2 \n",
    "import random \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "from PIL import Image \n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.callbacks import TensorBoard \n",
    "from sklearn.metrics import classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import hashlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4217 files belonging to 4 classes.\n",
      "Using 3374 files for training.\n"
     ]
    }
   ],
   "source": [
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    directory='D:/Kegiatan lain/Stechoq/dataset tugas akhir/dataset',\n",
    "    batch_size=32,\n",
    "    image_size=(256, 256),  # Target size for all images\n",
    "    validation_split=0.2,\n",
    "    subset='training',\n",
    "    seed=123,\n",
    "    label_mode='categorical'\n",
    ")\n",
    "\n",
    "# Function to check the shape of images in the dataset\n",
    "def check_shape(images, labels):\n",
    "    print(\"Image batch shape:\", images.shape)  # Print the shape of the image batch\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rescaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4217 files belonging to 4 classes.\n",
      "Using 3374 files for training.\n",
      "Found 4217 files belonging to 4 classes.\n",
      "Using 843 files for validation.\n",
      "Found 4217 files belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "rescale = tf.keras.layers.Rescaling(1./255)\n",
    "\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    directory = 'D:/Kegiatan lain/Stechoq/dataset tugas akhir/dataset',\n",
    "    batch_size = 32,\n",
    "    image_size = (256, 256),\n",
    "    validation_split = 0.2,\n",
    "    subset = 'training',\n",
    "    seed = 123,\n",
    "    label_mode = 'categorical'\n",
    ")\n",
    "\n",
    "train_ds = train_ds.map(lambda x, y: (rescale(x), y))\n",
    "\n",
    "validation_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    directory = 'D:/Kegiatan lain/Stechoq/dataset tugas akhir/dataset', \n",
    "    batch_size = 32, \n",
    "    image_size = (256, 256), \n",
    "    validation_split = 0.2, \n",
    "    subset = 'validation', \n",
    "    seed = 123, \n",
    "    label_mode = 'categorical'\n",
    ")\n",
    "\n",
    "validation_ds = validation_ds.map(lambda x, y: (rescale(x), y))\n",
    "\n",
    "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    directory='D:/Kegiatan lain/Stechoq/dataset tugas akhir/dataset',\n",
    "    batch_size=32, \n",
    "    image_size=(256, 256), \n",
    "    label_mode='categorical', \n",
    "    shuffle=False, \n",
    ")\n",
    "\n",
    "test_ds = test_ds.map(lambda x, y: (rescale(x), y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cek shape after preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the first image in the training dataset: (256, 256, 3)\n",
      "Shape of the first iage in the validation dataset: (256, 256, 3)\n",
      "Shape of the first image in the test dataset: (256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "#dataset train, validation, dan tes sudah diubah ukurannya menjadi 256x256 piksel dan memiliki 3 channel (format RGB)\n",
    "\n",
    "print('Shape of the first image in the training dataset:', next(iter(train_ds))[0][0].shape)\n",
    "print('Shape of the first iage in the validation dataset:', next(iter(validation_ds))[0][0].shape)\n",
    "print('Shape of the first image in the test dataset:', next(iter(test_ds))[0][0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check pixel value after preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum pixel value: 1.0\n",
      "Maaximum pixel value: 1.0\n"
     ]
    }
   ],
   "source": [
    "min_pixel_value = float('inf')\n",
    "max_pixel_value = float('-inf')\n",
    "\n",
    "for image, _ in train_ds: \n",
    "    batch_min = tf.reduce_min(image)\n",
    "    batch_max = tf.reduce_max(image)\n",
    "\n",
    "    min_pixel_value = tf.minimum(min_pixel_value, batch_min)\n",
    "    max_pixel_value = tf.maximum(max_pixel_value, batch_max)\n",
    "\n",
    "print('Minimum pixel value:', max_pixel_value.numpy())\n",
    "print('Maaximum pixel value:', max_pixel_value.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tidak ada gambar duplikat ditemukan.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import hashlib\n",
    "from PIL import Image\n",
    "\n",
    "def generate_image_hash(image_path):\n",
    "    \"\"\"Menghasilkan hash untuk gambar\"\"\"\n",
    "    try:\n",
    "        with Image.open(image_path) as img:\n",
    "            # Konversi gambar ke ukuran yang sama untuk membuat perbandingan lebih mudah\n",
    "            img = img.resize((256, 256))\n",
    "            img_hash = hashlib.md5(img.tobytes()).hexdigest()\n",
    "        return img_hash\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing image {image_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def find_duplicate_images(folder_path):\n",
    "    \"\"\"Mencari gambar duplikat dalam folder\"\"\"\n",
    "    hashes = {}\n",
    "    duplicates = []\n",
    "\n",
    "    # Iterasi melalui semua file dalam folder\n",
    "    for filename in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "\n",
    "        # Cek apakah file adalah gambar\n",
    "        if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif')):\n",
    "            img_hash = generate_image_hash(file_path)\n",
    "\n",
    "            # Lanjutkan jika hash berhasil dihasilkan\n",
    "            if img_hash:\n",
    "                # Cek apakah hash sudah ada di kamus\n",
    "                if img_hash in hashes:\n",
    "                    duplicates.append((file_path, hashes[img_hash]))\n",
    "                else:\n",
    "                    hashes[img_hash] = file_path\n",
    "\n",
    "    return duplicates\n",
    "\n",
    "# Penggunaan\n",
    "folder_path = 'D:/Kegiatan lain/Stechoq/dataset tugas akhir/dataset'  # Ganti dengan path folder Anda\n",
    "dups = find_duplicate_images(folder_path)\n",
    "\n",
    "if dups:\n",
    "    print(\"Gambar duplikat ditemukan:\")\n",
    "    for dup in dups:\n",
    "        print(f\"Duplikat: {dup[0]} adalah salinan dari {dup[1]}\")\n",
    "else:\n",
    "    print(\"Tidak ada gambar duplikat ditemukan.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grayscale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### grayscale cataract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proses selesai, citra grayscaale disimpan di folder output. \n"
     ]
    }
   ],
   "source": [
    "input_folder = 'D:/Kegiatan lain/Stechoq/dataset tugas akhir/dataset/cataract'\n",
    "output_folder = 'D:/Kegiatan lain/Stechoq/dataset tugas akhir/grayscale/cataract'\n",
    "\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "for filename in os.listdir(input_folder):\n",
    "    if filename.endswith(('.png', '.jpg', '.jpeg', '.bmp')):\n",
    "\n",
    "        img_path = os.path.join(input_folder, filename)\n",
    "        img = cv2.imread(img_path)\n",
    "\n",
    "        gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) \n",
    "\n",
    "        output_path = os.path.join(output_folder, filename)\n",
    "        cv2.imwrite(output_path, gray_img)\n",
    "\n",
    "print('Proses selesai, citra grayscaale disimpan di folder output. ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### gryascale diabetic_retinopathy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proses selesai, citra grayscaale disimpan di folder output. \n"
     ]
    }
   ],
   "source": [
    "input_folder = 'D:/Kegiatan lain/Stechoq/dataset tugas akhir/dataset/diabetic_retinopathy'\n",
    "output_folder = 'D:/Kegiatan lain/Stechoq/dataset tugas akhir/grayscale/diabetic_retinopathy'\n",
    "\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "for filename in os.listdir(input_folder):\n",
    "    if filename.endswith(('.png', '.jpg', '.jpeg', '.bmp')):\n",
    "\n",
    "        img_path = os.path.join(input_folder, filename)\n",
    "        img = cv2.imread(img_path)\n",
    "\n",
    "        gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) \n",
    "\n",
    "        output_path = os.path.join(output_folder, filename)\n",
    "        cv2.imwrite(output_path, gray_img)\n",
    "\n",
    "print('Proses selesai, citra grayscaale disimpan di folder output. ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### grayscale glaucoma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proses selesai, citra grayscaale disimpan di folder output. \n"
     ]
    }
   ],
   "source": [
    "input_folder = 'D:/Kegiatan lain/Stechoq/dataset tugas akhir/dataset/glaucoma'\n",
    "output_folder = 'D:/Kegiatan lain/Stechoq/dataset tugas akhir/grayscale/glaucoma'\n",
    "\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "for filename in os.listdir(input_folder):\n",
    "    if filename.endswith(('.png', '.jpg', '.jpeg', '.bmp')):\n",
    "\n",
    "        img_path = os.path.join(input_folder, filename)\n",
    "        img = cv2.imread(img_path)\n",
    "\n",
    "        gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) \n",
    "\n",
    "        output_path = os.path.join(output_folder, filename)\n",
    "        cv2.imwrite(output_path, gray_img)\n",
    "\n",
    "print('Proses selesai, citra grayscaale disimpan di folder output. ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### grayscale normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proses selesai, citra grayscaale disimpan di folder output. \n"
     ]
    }
   ],
   "source": [
    "input_folder = 'D:/Kegiatan lain/Stechoq/dataset tugas akhir/dataset/normal'\n",
    "output_folder = 'D:/Kegiatan lain/Stechoq/dataset tugas akhir/grayscale/normal'\n",
    "\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "for filename in os.listdir(input_folder):\n",
    "    if filename.endswith(('.png', '.jpg', '.jpeg', '.bmp')):\n",
    "\n",
    "        img_path = os.path.join(input_folder, filename)\n",
    "        img = cv2.imread(img_path)\n",
    "\n",
    "        gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) \n",
    "\n",
    "        output_path = os.path.join(output_folder, filename)\n",
    "        cv2.imwrite(output_path, gray_img)\n",
    "\n",
    "print('Proses selesai, citra grayscaale disimpan di folder output. ')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
